{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         17.99         10.38          122.80     1001.0          0.11840   \n",
       "0         20.57         17.77          132.90     1326.0          0.08474   \n",
       "0         19.69         21.25          130.00     1203.0          0.10960   \n",
       "0         11.42         20.38           77.58      386.1          0.14250   \n",
       "0         20.29         14.34          135.10     1297.0          0.10030   \n",
       "..          ...           ...             ...        ...              ...   \n",
       "0         21.56         22.39          142.00     1479.0          0.11100   \n",
       "0         20.13         28.25          131.20     1261.0          0.09780   \n",
       "0         16.60         28.08          108.30      858.1          0.08455   \n",
       "0         20.60         29.33          140.10     1265.0          0.11780   \n",
       "1          7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.27760         0.30010              0.14710         0.2419   \n",
       "0            0.07864         0.08690              0.07017         0.1812   \n",
       "0            0.15990         0.19740              0.12790         0.2069   \n",
       "0            0.28390         0.24140              0.10520         0.2597   \n",
       "0            0.13280         0.19800              0.10430         0.1809   \n",
       "..               ...             ...                  ...            ...   \n",
       "0            0.11590         0.24390              0.13890         0.1726   \n",
       "0            0.10340         0.14400              0.09791         0.1752   \n",
       "0            0.10230         0.09251              0.05302         0.1590   \n",
       "0            0.27700         0.35140              0.15200         0.2397   \n",
       "1            0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "    mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                  0.07871  ...        25.380          17.33           184.60   \n",
       "0                  0.05667  ...        24.990          23.41           158.80   \n",
       "0                  0.05999  ...        23.570          25.53           152.50   \n",
       "0                  0.09744  ...        14.910          26.50            98.87   \n",
       "0                  0.05883  ...        22.540          16.67           152.20   \n",
       "..                     ...  ...           ...            ...              ...   \n",
       "0                  0.05623  ...        25.450          26.40           166.10   \n",
       "0                  0.05533  ...        23.690          38.25           155.00   \n",
       "0                  0.05648  ...        18.980          34.12           126.70   \n",
       "0                  0.07016  ...        25.740          39.42           184.60   \n",
       "1                  0.05884  ...         9.456          30.37            59.16   \n",
       "\n",
       "    worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0       2019.0           0.16220            0.66560           0.7119   \n",
       "0       1956.0           0.12380            0.18660           0.2416   \n",
       "0       1709.0           0.14440            0.42450           0.4504   \n",
       "0        567.7           0.20980            0.86630           0.6869   \n",
       "0       1575.0           0.13740            0.20500           0.4000   \n",
       "..         ...               ...                ...              ...   \n",
       "0       2027.0           0.14100            0.21130           0.4107   \n",
       "0       1731.0           0.11660            0.19220           0.3215   \n",
       "0       1124.0           0.11390            0.30940           0.3403   \n",
       "0       1821.0           0.16500            0.86810           0.9387   \n",
       "1        268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "    worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                 0.2654          0.4601                  0.11890  \n",
       "0                 0.1860          0.2750                  0.08902  \n",
       "0                 0.2430          0.3613                  0.08758  \n",
       "0                 0.2575          0.6638                  0.17300  \n",
       "0                 0.1625          0.2364                  0.07678  \n",
       "..                   ...             ...                      ...  \n",
       "0                 0.2216          0.2060                  0.07115  \n",
       "0                 0.1628          0.2572                  0.06637  \n",
       "0                 0.1418          0.2218                  0.07820  \n",
       "0                 0.2650          0.4087                  0.12400  \n",
       "1                 0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data=datasets.load_breast_cancer()\n",
    "import pandas as pd\n",
    "X=data.data\n",
    "y=data.target\n",
    "data=pd.DataFrame(X,y,columns=data.feature_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "penalty='none' is not supported for the liblinear solver",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-a926cc75657c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mLogReg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"multinomial\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"none\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mLogReg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m         \"\"\"\n\u001b[1;32m-> 1493\u001b[1;33m         \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'liblinear'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         raise ValueError(\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[1;34m\"penalty='none' is not supported for the liblinear solver\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m         )\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: penalty='none' is not supported for the liblinear solver"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "LogReg = LogisticRegression( multi_class = \"multinomial\", penalty=\"none\")\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = LogReg.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(cnf_matrix, annot=True, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
